{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cb09d4",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo\n",
    "\n",
    "Este notebook carga los datos de taxi de enero de 2020, aplica preprocesamiento, entrena un modelo Random Forest y evalúa su desempeño con F1-score. También permite automatizar la evaluación del modelo entrenado sobre otros meses del año.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145f0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import load_and_clean_data\n",
    "from src.features.build_features import preprocess, get_feature_names\n",
    "from src.modeling.train import train_model\n",
    "from src.modeling.predict import evaluate_model\n",
    "\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a1b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"raw\", \"yellow_tripdata_2020-01.parquet\")\n",
    "MODEL_PATH = os.path.join(PROJECT_ROOT, \"models\", \"model_jan.pkl\")\n",
    "TARGET_COL = \"high_tip\"\n",
    "SAMPLE_SIZE = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c0d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data(DATA_PATH)\n",
    "df = df.head(SAMPLE_SIZE)  # muestra para probar\n",
    "df = preprocess(df, target_col=TARGET_COL)\n",
    "\n",
    "features = get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aac381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_test, y_test = train_model(df, features, TARGET_COL, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbaa8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55      9805\n",
      "           1       0.57      0.58      0.58     10099\n",
      "\n",
      "    accuracy                           0.56     19904\n",
      "   macro avg       0.56      0.56      0.56     19904\n",
      "weighted avg       0.56      0.56      0.56     19904\n",
      "\n",
      "F1-score enero: 0.5753\n"
     ]
    }
   ],
   "source": [
    "f1 = evaluate_model(MODEL_PATH, X_test, y_test)\n",
    "print(f\"F1-score enero: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7f57a",
   "metadata": {},
   "source": [
    "## Evaluación del modelo en el conjunto de entrenamiento (enero 2020)\n",
    "\n",
    "Tras entrenar el modelo con datos de enero de 2020, se evaluó su rendimiento sobre una partición de test del mismo mes. Los resultados obtenidos son:\n",
    "\n",
    "          precision    recall  f1-score   support\n",
    "\n",
    "       0       0.56      0.54      0.55      9805\n",
    "       1       0.57      0.58      0.58     10099\n",
    "\n",
    "accuracy                           0.56     19904\n",
    "\n",
    "\n",
    "\n",
    "**F1-score promedio (clase 1): 0.5753**\n",
    "\n",
    "### Interpretación\n",
    "\n",
    "- El modelo muestra un rendimiento **modesto** incluso sobre los datos de su mismo mes de entrenamiento, lo que sugiere que el problema es **intrínsecamente difícil de predecir** (por ejemplo, porque las propinas son altamente variables o influenciadas por factores no observados).\n",
    "- El F1-score ligeramente mayor para la clase 1 (`high_tip`) sugiere que el modelo tiene una leve mejor capacidad para detectar viajes con alta propina que sin ella, pero no de forma determinante.\n",
    "- El **balance de clases es razonablemente parejo**, lo que valida el uso de F1 como métrica.\n",
    "\n",
    "### Próximo paso\n",
    "\n",
    "Evaluar este mismo modelo sobre datos de **febrero**, para detectar si hay **degradación de rendimiento temporal** o patrones consistentes en los errores del modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
